{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# perceptron in scikit with single tlu network\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length and width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, .5]])\n",
    "print(y_pred)\n",
    "# perceptron does not output a class probability like logistic regression\n",
    "# but uses a hard threshold classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use nonlinear activations functions in mlps like sigmoid, hyperbolic tangent, relu because\n",
    "# linear transformations of multiple linear functions are still linear. by nesting the\n",
    "# above activation functions in each layer, you can basically approximate any continuous function\n",
    "\n",
    "# a typical regression mlp follows this format\n",
    "# input neurons : one per feature\n",
    "# hidden layers: typically 1 to 5\n",
    "# neurons per hidden layer : typically 10 to 100\n",
    "# output neurons : 1 per prediction dimension\n",
    "# hidden activation : ReLU\n",
    "# output activation: None, or relu/softplus if positive only outputs or logistic/tanh if bounded outputs\n",
    "# loss function: MSE or MAE/Huber if outliers\n",
    "\n",
    "\n",
    "# classification mlp\n",
    "# input and hidden layers: same as regression\n",
    "# output neurons: 1 for binary classification, 1 per label for multilabel binary, 1 per class for multiclass\n",
    "# output layer activation: logistic for binary and multilabel binary, softmax for multiclass\n",
    "# loss function: cross entropy\n",
    "# use softmax for multiclass because if the classes are exclusive the sum of all \n",
    "# output neurons will be 1. for multilabel and binary classes, you can you log because they may not be exclusive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow and keras time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we will build an image classifier\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    }
   ],
   "source": [
    "# X_train_full.shape\n",
    "# X_train_full.dtype\n",
    "\n",
    "# split train set into validation and train / scale pixel intensities by dividing by 255.0\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# get the class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print(class_names[y_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build the neural net. classification mlp with 2 hidden layers\n",
    "\n",
    "model = keras.models.Sequential() # create sequential model\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28])) # convert image into 1d array\n",
    "model.add(keras.layers.Dense(300, activation='relu')) # dense layer, 300 neurons, relu activation\n",
    "model.add(keras.layers.Dense(100, activation='relu')) # dense layer, 100 neurons, relu\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # 10 output neurons, softmax because exclusivity of class\n",
    "# each dense layer manages its own weight matrix containing all connection weights between the neurons and\n",
    "# their inputs. it also manages a vector of bias terms (one per neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of adding layers one by one, we could just do it this way\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])\n",
    "# use sparse categorical crossentropy because we have sparse labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7259 - accuracy: 0.7622 - val_loss: 0.5389 - val_accuracy: 0.8220\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4896 - accuracy: 0.8289 - val_loss: 0.4665 - val_accuracy: 0.8406\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4474 - accuracy: 0.8433 - val_loss: 0.4302 - val_accuracy: 0.8550\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4191 - accuracy: 0.8527 - val_loss: 0.4006 - val_accuracy: 0.8648\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3992 - accuracy: 0.8606 - val_loss: 0.3932 - val_accuracy: 0.8638\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3826 - accuracy: 0.8651 - val_loss: 0.3796 - val_accuracy: 0.8662\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3685 - accuracy: 0.8707 - val_loss: 0.3816 - val_accuracy: 0.8668\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3570 - accuracy: 0.8730 - val_loss: 0.3712 - val_accuracy: 0.8672\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3462 - accuracy: 0.8770 - val_loss: 0.3723 - val_accuracy: 0.8682\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3370 - accuracy: 0.8810 - val_loss: 0.3418 - val_accuracy: 0.8812\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3282 - accuracy: 0.8818 - val_loss: 0.3390 - val_accuracy: 0.8790\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3205 - accuracy: 0.8863 - val_loss: 0.3296 - val_accuracy: 0.8818\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3134 - accuracy: 0.8883 - val_loss: 0.3286 - val_accuracy: 0.8824\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3065 - accuracy: 0.8896 - val_loss: 0.3335 - val_accuracy: 0.8858\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2990 - accuracy: 0.8925 - val_loss: 0.3306 - val_accuracy: 0.8812\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2938 - accuracy: 0.8934 - val_loss: 0.3203 - val_accuracy: 0.8822\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2881 - accuracy: 0.8962 - val_loss: 0.3231 - val_accuracy: 0.8856\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2820 - accuracy: 0.8977 - val_loss: 0.3177 - val_accuracy: 0.8848\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2774 - accuracy: 0.9003 - val_loss: 0.3197 - val_accuracy: 0.8856\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2724 - accuracy: 0.9017 - val_loss: 0.3132 - val_accuracy: 0.8874\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2667 - accuracy: 0.9035 - val_loss: 0.3133 - val_accuracy: 0.8896\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2627 - accuracy: 0.9051 - val_loss: 0.3134 - val_accuracy: 0.8866\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2580 - accuracy: 0.9074 - val_loss: 0.3034 - val_accuracy: 0.8906\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2530 - accuracy: 0.9089 - val_loss: 0.2978 - val_accuracy: 0.8946\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2487 - accuracy: 0.9092 - val_loss: 0.3072 - val_accuracy: 0.8916\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2445 - accuracy: 0.9120 - val_loss: 0.2941 - val_accuracy: 0.8960\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2419 - accuracy: 0.9117 - val_loss: 0.3105 - val_accuracy: 0.8892\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2364 - accuracy: 0.9146 - val_loss: 0.3073 - val_accuracy: 0.8894\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2322 - accuracy: 0.9162 - val_loss: 0.2962 - val_accuracy: 0.8904\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2286 - accuracy: 0.9177 - val_loss: 0.2946 - val_accuracy: 0.8964\n",
      "<keras.callbacks.History object at 0x7fe32817eeb0>\n"
     ]
    }
   ],
   "source": [
    "# now to train the model\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, \n",
    "                   validation_data=(X_valid, y_valid))\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a closer look at the model history\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1645411b72ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to use the model to make predictions\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building regression ann\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<keras.layers.core.dense.Dense object at 0x7f813588b3d0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e14254928f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# use mse loss for regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m history = model.fit(X_train, y_train, epochs=20,\n\u001b[1;32m     16\u001b[0m                    validation_data=(X_valid, y_valid))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# only one output neuron for regression with no activation function\n",
    "\n",
    "# we will use only 1 hidden layer with a small number of neurons to avoid overfitting this noisy dataset\n",
    "\n",
    "model = keras.models.Sequential = ([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "print(len(model))\n",
    "print(model[0])\n",
    "# use mse loss for regression\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n"
     ]
    }
   ],
   "source": [
    "# keras functional api\n",
    "\n",
    "# wide and deep neural network to allow input reach end without being distorted\n",
    "# we will get the complex patterns from the deeper hidden layers and the \n",
    "# simple patterns from feeding the input layer to the concat layer\n",
    "print(X_train.shape)\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we wanted to subset the features so that some go wide and some go deep of the hidden layers?\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frel/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2119 - val_loss: 0.9806\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.8013 - val_loss: 0.6883\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.6343 - val_loss: 0.6115\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.5821 - val_loss: 0.5716\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5495\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.5285 - val_loss: 0.5241\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.5117 - val_loss: 0.5070\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.4993 - val_loss: 0.4961\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.4903 - val_loss: 0.4882\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4829 - val_loss: 0.4848\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.4779 - val_loss: 0.4750\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 0.4704\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.4701 - val_loss: 0.4702\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.4672 - val_loss: 0.4674\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 838us/step - loss: 0.4648 - val_loss: 0.4661\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.4627 - val_loss: 0.4635\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.4605 - val_loss: 0.4614\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.4590 - val_loss: 0.4635\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.4571 - val_loss: 0.4596\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 837us/step - loss: 0.4557 - val_loss: 0.4620\n",
      "162/162 [==============================] - 0s 585us/step - loss: 0.5043\n"
     ]
    }
   ],
   "source": [
    "# now we must pass the model a pair of matrices A and B\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                   validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8193 - main_output_loss: 0.7683 - aux_output_loss: 1.2780 - val_loss: 0.5092 - val_main_output_loss: 0.4737 - val_aux_output_loss: 0.8288\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4844 - main_output_loss: 0.4512 - aux_output_loss: 0.7835 - val_loss: 0.5729 - val_main_output_loss: 0.5462 - val_aux_output_loss: 0.8131\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.4642 - main_output_loss: 0.4369 - aux_output_loss: 0.7100 - val_loss: 0.6004 - val_main_output_loss: 0.5766 - val_aux_output_loss: 0.8144\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.4513 - main_output_loss: 0.4274 - aux_output_loss: 0.6659 - val_loss: 0.6593 - val_main_output_loss: 0.6371 - val_aux_output_loss: 0.8590\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.4439 - main_output_loss: 0.4224 - aux_output_loss: 0.6379 - val_loss: 0.7316 - val_main_output_loss: 0.7081 - val_aux_output_loss: 0.9434\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.4322 - main_output_loss: 0.4115 - aux_output_loss: 0.6189 - val_loss: 0.8232 - val_main_output_loss: 0.7968 - val_aux_output_loss: 1.0605\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.4292 - main_output_loss: 0.4099 - aux_output_loss: 0.6031 - val_loss: 0.9101 - val_main_output_loss: 0.8851 - val_aux_output_loss: 1.1347\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4174 - main_output_loss: 0.3984 - aux_output_loss: 0.5878 - val_loss: 1.0162 - val_main_output_loss: 0.9869 - val_aux_output_loss: 1.2805\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.4093 - main_output_loss: 0.3907 - aux_output_loss: 0.5769 - val_loss: 1.1615 - val_main_output_loss: 1.1314 - val_aux_output_loss: 1.4324\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4033 - main_output_loss: 0.3853 - aux_output_loss: 0.5649 - val_loss: 1.4309 - val_main_output_loss: 1.4037 - val_aux_output_loss: 1.6759\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4005 - main_output_loss: 0.3830 - aux_output_loss: 0.5574 - val_loss: 1.5609 - val_main_output_loss: 1.5339 - val_aux_output_loss: 1.8047\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.3966 - main_output_loss: 0.3797 - aux_output_loss: 0.5490 - val_loss: 1.7640 - val_main_output_loss: 1.7338 - val_aux_output_loss: 2.0354\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3888 - main_output_loss: 0.3719 - aux_output_loss: 0.5410 - val_loss: 1.9590 - val_main_output_loss: 1.9254 - val_aux_output_loss: 2.2611\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3841 - main_output_loss: 0.3676 - aux_output_loss: 0.5321 - val_loss: 2.1429 - val_main_output_loss: 2.1108 - val_aux_output_loss: 2.4320\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3788 - main_output_loss: 0.3627 - aux_output_loss: 0.5235 - val_loss: 2.7363 - val_main_output_loss: 2.7144 - val_aux_output_loss: 2.9336\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3775 - main_output_loss: 0.3620 - aux_output_loss: 0.5171 - val_loss: 2.7906 - val_main_output_loss: 2.7633 - val_aux_output_loss: 3.0369\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.3711 - main_output_loss: 0.3555 - aux_output_loss: 0.5117 - val_loss: 3.1442 - val_main_output_loss: 3.1246 - val_aux_output_loss: 3.3211\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3735 - main_output_loss: 0.3586 - aux_output_loss: 0.5075 - val_loss: 3.3949 - val_main_output_loss: 3.3797 - val_aux_output_loss: 3.5320\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3629 - main_output_loss: 0.3481 - aux_output_loss: 0.4960 - val_loss: 3.8144 - val_main_output_loss: 3.8082 - val_aux_output_loss: 3.8705\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3693 - main_output_loss: 0.3549 - aux_output_loss: 0.4984 - val_loss: 3.9279 - val_main_output_loss: 3.9270 - val_aux_output_loss: 3.9364\n"
     ]
    }
   ],
   "source": [
    "# what if you want to output a layer for regularization?\n",
    "\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n",
    "# have to pass multiple loss functions and loss weights now\n",
    "\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[.9, .1], optimizer='sgd')\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 722us/step - loss: 8.3940 - main_output_loss: 8.3772 - aux_output_loss: 8.5455\n"
     ]
    }
   ],
   "source": [
    "# predict will return predictions for each output\n",
    "\n",
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
